这份文档是同济大学倪张凯教授的机器学习课程第10章“聚类”的讲义，按页码顺序（对应文档逻辑顺序），核心内容可分为**基础概念、聚类类型、核心算法、有效性评估、结论**五大模块，详细拆解如下：


### 一、基础铺垫：聚类的定位、定义与核心认知（第1-6页）
#### 1. 机器学习问题分类（第1-2页）
机器学习分为两大核心方向，聚类属于**无监督学习**：
| 监督学习（有标签） | 无监督学习（无标签） |
|--------------------|--------------------|
| 分类/归类（Classification） | 聚类（Clustering） |
| 回归（Regression）         | 降维（Dimensionality Reduction） |

#### 2. 聚类分析的定义（第3页）
- 核心目标：将对象划分为若干“簇（Cluster）”，满足**组内（Intra-cluster）对象相似/相关，组间（Inter-cluster）对象不同/不相关**。
- 量化目标：组内距离最小化，组间距离最大化。

#### 3. 聚类的典型应用（第4页）
- 推荐系统与广告：用户聚类（精准推荐）、物品聚类（关联推荐）；
- 文本挖掘：文档聚类（相关搜索）、单词聚类（查询推荐）；
- 图像搜索：相似图像匹配、重复检测；
- 语音处理：语音特征聚类（识别/分离）。

#### 4. 聚类的模糊性（第5页）
聚类的核心争议：**“到底该分多少个簇？”**  
文档以同一组数据为例，展示了“2个簇、4个簇、6个簇”的不同划分可能，说明聚类结果无绝对唯一答案，需结合场景判断。

#### 5. 好聚类的评价标准（第6页）
- 核心指标：高组内相似度（Intra-class Similarity）、低组间相似度（Inter-class Similarity）；
- 影响因素：相似度度量方法、算法实现；
- 关键能力：能发现数据中隐藏的真实模式。


### 二、核心基础：聚类方法分类与簇的类型（第7-13页）
#### 1. 六大聚类方法体系（第7-8页）
文档将聚类算法按核心思想分为6类，明确每类的逻辑和典型方法：
| 聚类方法类型       | 核心思想                                                                 | 典型算法                                  |
|--------------------|--------------------------------------------------------------------------|-------------------------------------------|
| 划分方法（Partitioning） | 构建多个数据分区，用准则（如最小化平方误差）评估分区质量                 | K-means、ISODATA、k-medoids、Kernel K-means、CLARANS |
| 层次方法（Hierarchical） | 构建数据的层次分解（树状结构），按“合并”或“拆分”思路迭代                 | Agnes、Diana、BIRCH、ROCK、CAMELEON        |
| 密度方法（Density-based） | 基于数据密度（高密度区域为簇，低密度区域为分隔）                         | DBSCAN、OPTICS、DenClue                    |
| 网格方法（Grid-based）   | 基于多层粒度的网格结构划分数据                                           | STING、WaveCluster、CLIQUE                 |
| 基于模型（Model-based）  | 为每个簇假设一个模型（如概率模型），寻找数据与模型的最佳拟合             | EM、SOM、COBWEB                            |
| 基于频繁模式（Frequent pattern-based） | 通过分析数据中的频繁共现模式划分簇                                       | pCluster                                  |

#### 2. 五种簇的类型（第9-13页）
簇的类型决定了聚类算法的选择，文档定义了5类典型簇结构：
- **完全分离簇（Well-Separated）**：簇内任意点与簇内其他点的距离，小于与簇外任意点的距离（示例：3个独立簇）；
- **基于中心的簇（Center-based）**：簇内所有点更接近簇的“中心”（质心/代表点medoid），而非其他簇的中心（示例：4个球形簇）；
- **基于邻接的簇（Contiguity-based）**：簇是“连通组件”，簇内点至少与一个簇内点邻近，与簇外点不连通（示例：8个链式簇）；
- **基于密度的簇（Density-based）**：高密度区域被低密度区域分隔，适用于不规则、交织的簇，能容忍噪声（示例：6个非球形簇）；
- **基于概念的簇（Conceptual）**：簇内对象共享共同属性或概念（示例：2个重叠的圆簇）。


### 三、核心算法1：K-means聚类（第14-25页）
K-means是最常用的划分式聚类算法，文档详细讲解了其原理、细节、问题与解决方案：

#### 1. 核心原理与步骤（第14页）
- 前提：需预先指定簇数K；
- 核心：以“质心（簇内所有点的均值）”为核心，迭代优化簇分配；
- 算法步骤：
  1. 随机选择K个点作为初始质心；
  2. 迭代：将所有数据点分配到“最近的质心”，形成K个簇；
  3. 重新计算每个簇的质心（更新为簇内点的均值）；
  4. 停止条件：质心不再变化（或“少数点改变簇分配”）。

#### 2. 关键细节（第15页）
- 相似度度量：常用欧氏距离、余弦相似度；
- 收敛性：对常见相似度度量，算法一定收敛（多数收敛发生在前期迭代）；
- 时间复杂度：\(O(n \times K \times I \times d)\)（n=数据点数，K=簇数，I=迭代次数，d=数据维度）。

#### 3. 相似度度量公式（第16-17页）
- **欧氏距离**（衡量连续数据的物理距离）：  
  \[d(x, y)=\sqrt{\sum_{k=1}^{n}\left(x_{k}-y_{k}\right)^{2}}\]
- **余弦相似度**（衡量高维数据（如文档）的方向一致性）：  
  对两个文档向量\(d_1(x)\)和\(d_2(y)\)，相似度为：  
  \[cos(x,y)=\frac{x \cdot y}{\|x\| \cdot \|y\|}\]  
  示例：若\(x=[3,2,0,5,0,...0]\)、\(y=[1,0,0,...0,1,0,2]\)，计算得\(cos(x,y)=0.3150\)。

#### 4. 核心问题与解决方案（第18-24页）
| 问题                | 具体描述                                                                 | 解决方案                                                                 |
|---------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|
| 初始质心敏感        | 随机选初始质心，导致结果不稳定；K越大，选到“最优初始质心”的概率越低（K=10时概率仅0.00036） | 1. 多次运行取最优；2. 采样+层次聚类确定初始质心；3. 选多组初始质心再筛选；4. 用二分K-means |
| 空簇问题            | 迭代中可能出现无数据点的空簇                                             | 1. 选对SSE贡献最大的点补入；2. 从SSE最高的簇中选点补入                   |
| 数据预处理需求      | 不同维度量级差异、异常值会影响结果                                       | 预处理：数据归一化、消除异常值；后处理：拆分松散簇、合并邻近簇、删除小簇 |

#### 5. 变体：二分K-means（第20页）
- 核心改进：避免初始质心敏感，通过“拆分”替代“直接分配”；
- 步骤：1. 初始为1个全量数据簇；2. 迭代：选1个簇用K-means拆分为2个；3. 保留拆分后SSE最小的两个簇；4. 重复直到簇数为K；
- 优势：对初始质心不敏感，结果更稳定。

#### 6. K-means的局限性（第25页）
- 仅适用于**球形、等大小、等密度**的簇；
- 对异常值敏感；
- 无法处理非球形、交织的簇。


### 四、核心算法2：层次聚类（第26-50页）
层次聚类通过构建“树状图（Dendrogram）”呈现簇的嵌套关系，文档从原理、类型、方法到局限全面讲解：

#### 1. 核心特点（第26-28页）
- 输出：树状图（纵轴为距离/相似度，横轴为数据点，可通过“切割树状图”得到任意数量的簇）；
- 优势：1. 无需预先指定簇数；2. 结果对应有意义的分类法（如生物学分类）；3. 可视化效果好。

#### 2. 两大类型（第29页）
| 类型         | 核心思路                                                                 | 步骤                                                                 |
|--------------|--------------------------------------------------------------------------|----------------------------------------------------------------------|
| 凝聚型（Agglomerative） | 自底向上：每个点初始为1个簇，每次合并“最近的两个簇”，直到1个簇（或K个簇） | 1. 计算邻近矩阵；2. 单点为簇；3. 迭代合并最近簇+更新邻近矩阵；4. 停止 |
| 分裂型（Divisive）     | 自顶向下：初始为1个全量簇，每次拆分1个簇，直到单点簇（或K个簇）           | 1. 全量数据为1个簇；2. 迭代拆分簇+更新邻近矩阵；3. 停止             |

#### 3. 关键：簇间相似度定义（第35-47页）
层次聚类的核心是“如何定义两个簇的距离”，文档给出5种经典方法：
| 簇间距离方法 | 核心逻辑                                                                 | 优势                                  | 局限性                                  |
|--------------|--------------------------------------------------------------------------|---------------------------------------|-----------------------------------------|
| MIN（单链接） | 两簇的距离=簇内最近两点的距离                                             | 能处理非椭圆簇                        | 对噪声、异常值敏感，易产生“链状簇”      |
| MAX（完全链接） | 两簇的距离=簇内最远两点的距离                                             | 对噪声、异常值不敏感                  | 倾向拆分大簇，偏向球形簇                |
| 组平均（Group Average） | 两簇的距离=簇内所有点对距离的平均值                                       | 折中方案，噪声鲁棒性中等              | 偏向球形簇                              |
| 质心距离     | 两簇的距离=两簇质心的距离                                                 | 计算简单                              | 对异常值敏感                            |
| Ward方法     | 两簇的相似度=合并后平方误差（SSE）的增加量                                 | 噪声鲁棒性强，与K-means逻辑一致        | 偏向球形簇，可用于K-means初始质心选择    |

#### 4. 复杂度与局限性（第49-50页）
- 复杂度：空间复杂度\(O(N^2)\)（需存储邻近矩阵），时间复杂度\(O(N^3)\)（N为数据点数），部分方法可优化至\(O(N^2logN)\)；
- 核心局限：1. 合并/拆分决策不可逆（一旦合并，无法拆分）；2. 难以处理不同大小、不同密度的簇；3. 对噪声和异常值的鲁棒性依赖距离方法。


### 五、核心算法3：密度聚类（DBSCAN）（第51-57页）
密度聚类针对“非球形、含噪声”的数据，文档以DBSCAN为核心展开：

#### 1. 核心思想（第51-52页）
- 簇的定义：高密度区域（点的密度远高于周围），被低密度区域分隔；
- 核心优势：1. 无需指定簇数；2. 能发现任意形状的簇；3. 自动识别噪声；4. 一次扫描数据即可。

#### 2. DBSCAN关键定义（第53-54页）
- 参数：半径Eps（邻域范围）、最小点数MinPts（高密度阈值）；
- 点的分类：
  - 核心点：Eps邻域内的点数≥MinPts（簇的核心区域）；
  - 边界点：Eps邻域内的点数<MinPts，但在核心点的邻域内（簇的边缘）；
  - 噪声点：既非核心点也非边界点（被舍弃）。

#### 3. DBSCAN算法步骤（第55页）
1. 遍历所有点，标记核心点、边界点、噪声点；
2. 消除噪声点；
3. 对未标记簇的核心点，创建新簇，将其Eps邻域内所有点（核心点/边界点）划入该簇；
4. 重复直到所有核心点都有簇标签。

#### 4. 适用局限与参数选择（第56-57页）
- 局限：1. 对参数Eps和MinPts敏感；2. 数据密度不均匀时表现差；3. 高维数据中距离度量失效；
- 参数选择方法：绘制“每个点到其k近邻的距离排序图”，图中“拐点”对应的距离即为Eps（k=MinPts）。


### 六、聚类有效性评估（第58-66页）
聚类是无监督学习，需通过量化指标评估结果好坏，文档将评估指标分为3类，并给出可视化方法：

#### 1. 评估指标分类（第59页）
| 指标类型   | 核心用途                                                                 | 典型指标                                  |
|------------|--------------------------------------------------------------------------|-------------------------------------------|
| 外部指标   | 对比聚类结果与“真实标签”（如人工标注）的匹配度                           | Jaccard系数、互信息、Fowlkes-Mallows指数、Rand指数、熵 |
| 内部指标   | 仅基于数据本身，评估簇的紧凑性和分离度                                   | 轮廓系数、Calinski-Harabasz指数、SSE、Davies-Bouldin指数、Dunn指数 |
| 相对指标   | 比较两个不同聚类结果的优劣（如不同算法、不同参数）                       | 用外部/内部指标（如SSE、熵）直接对比       |

#### 2. 可视化评估方法（第60-64页）
- 基于相关性：构建“邻近矩阵（真实相似度）”和“关联矩阵（聚类结果是否同簇）”，计算两矩阵的相关性（高相关性=聚类结果好）；
- 基于相似度矩阵可视化：按聚类标签排序相似度矩阵，若簇内点相似度高（颜色深）、簇间相似度低（颜色浅），则聚类效果好。

#### 3. 常用内部指标：SSE（第65-66页）
- 定义：\(SSE=\sum_{i=1}^{K}\sum_{x \in C_i}dist^2(m_i,x)\)（\(m_i\)为簇\(C_i\)的质心）；
- 用途：1. 比较两个聚类结果（SSE越小，簇越紧凑）；2. 估计簇数K（SSE曲线的“拐点”对应最优K）。


### 七、结论（第67页）
文档总结了聚类的核心框架：
1. 聚类本质：无监督、离散的数据分析方法；
2. 核心算法体系：划分方法（K-means等）、层次方法（Agnes等）、密度方法（DBSCAN等）；
3. 有效性评估核心指标：外部指标（Jaccard系数等）、内部指标（SSE等）、相对指标（SSE/熵）。